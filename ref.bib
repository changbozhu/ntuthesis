% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

%{AMS}
@String{AMSTrans = "American Mathematical Society Translations" }
@String{AMSTrans = "Amer. Math. Soc. Transl." }
@String{BullAMS = "Bulletin of the American Mathematical Society" }
@String{BullAMS = "Bull. Amer. Math. Soc." }
@String{ProcAMS = "Proceedings of the American Mathematical Society" }
@String{ProcAMS = "Proc. Amer. Math. Soc." }
@String{TransAMS = "Transactions of the American Mathematical Society" }
@String{TransAMS = "Trans. Amer. Math. Soc." }

%ACM
@String{CACM = "Communications of the {ACM}" }
@String{CACM = "Commun. {ACM}" }
@String{CompServ = "Comput. Surveys" }
@String{JACM = "J. ACM" }
@String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
@String{ACMMathSoft = "{ACM} Trans. Math. Software" }
@String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
@String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

@String{AmerSocio = "American Journal of Sociology" }
@String{AmerStatAssoc = "Journal of the American Statistical Association" }
@String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
@String{ApplMathComp = "Applied Mathematics and Computation" }
@String{ApplMathComp = "Appl. Math. Comput." }
@String{AmerMathMonthly = "American Mathematical Monthly" }
@String{AmerMathMonthly = "Amer. Math. Monthly" }
@String{BIT = "{BIT}" }
@String{BritStatPsych = "British Journal of Mathematical and Statistical
	Psychology" }
@String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
@String{CanMathBull = "Canadian Mathematical Bulletin" }
@String{CanMathBull = "Canad. Math. Bull." }
@String{CompApplMath = "Journal of Computational and Applied Mathematics" }
@String{CompApplMath = "J. Comput. Appl. Math." }
@String{CompPhys = "Journal of Computational Physics" }
@String{CompPhys = "J. Comput. Phys." }
@String{CompStruct = "Computers and Structures" }
@String{CompStruct = "Comput. \& Structures" }
@String{CompJour = "The Computer Journal" }
@String{CompJour = "Comput. J." }
@String{CompSysSci = "Journal of Computer and System Sciences" }
@String{CompSysSci = "J. Comput. System Sci." }
@String{Computing = "Computing" }
@String{ContempMath = "Contemporary Mathematics" }
@String{ContempMath = "Contemp. Math." }
@String{Crelle = "Crelle's Journal" }
@String{GiornaleMath = "Giornale di Mathematiche" }
@String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

%IEEE
@String{Computer = "{IEEE} Computer" }
@String{IEEETransComp = "{IEEE} Transactions on Computers" }
@String{IEEETransComp = "{IEEE} Trans. Comput." }
@String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
@String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
@String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
@String{ProcIEEE = "Proceedings of the {IEEE}" }
@String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
@String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic Systems" }
@String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

@String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
@String{IMANumerAna = "{IMA} J. Numer. Anal." }
@String{InfProcLet = "Information Processing Letters" }
@String{InfProcLet = "Inform. Process. Lett." }
@String{InstMathApp = "Journal of the Institute of Mathematics and its Applications" }
@String{InstMathApp = "J. Inst. Math. Appl." }
@String{IntControl = "International Journal of Control" }
@String{IntControl = "Internat. J. Control" }
@String{IntNumerEng = "International Journal for Numerical Methods in Engineering" }
@String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
@String{IntSuper = "International Journal of Supercomputing Applications" }
@String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
@String{Kibernetika = "Kibernetika" }
@String{JResNatBurStand = "Journal of Research of the National Bureau of Standards" }
@String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
@String{LinAlgApp = "Linear Algebra and its Applications" }
@String{LinAlgApp = "Linear Algebra Appl." }
@String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
@String{MathAnaAppl = "J. Math. Anal. Appl." }
@String{MathAnnalen = "Mathematische Annalen" }
@String{MathAnnalen = "Math. Ann." }
@String{MathPhys = "Journal of Mathematical Physics" }
@String{MathPhys = "J. Math. Phys." }
@String{MathComp = "Mathematics of Computation" }
@String{MathComp = "Math. Comp." }
@String{MathScand = "Mathematica Scandinavica" }
@String{MathScand = "Math. Scand." }
@String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
@String{TablesAidsComp = "Math. Tables Aids Comput." }
@String{NumerMath = "Numerische Mathematik" }
@String{NumerMath = "Numer. Math." }
@String{PacificMath = "Pacific Journal of Mathematics" }
@String{PacificMath = "Pacific J. Math." }
@String{ParDistComp = "Journal of Parallel and Distributed Computing" }
@String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
@String{ParComputing = "Parallel Computing" }
@String{ParComputing = "Parallel Comput." }
@String{PhilMag = "Philosophical Magazine" }
@String{PhilMag = "Philos. Mag." }
@String{ProcNAS = "Proceedings of the National Academy of Sciences of the USA" }
@String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
@String{Psychometrika = "Psychometrika" }
@String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
@String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
@String{QuartApplMath = "Quarterly of Applied Mathematics" }
@String{QuartApplMath = "Quart. Appl. Math." }
@String{RevueInstStat = "Review of the International Statisical Institute" }
@String{RevueInstStat = "Rev. Inst. Internat. Statist." }

%SIAM
@String{JSIAM = "Journal of the Society for Industrial and Applied Mathematics" }
@String{JSIAM = "J. Soc. Indust. Appl. Math." }
@String{JSIAMB = "Journal of the Society for Industrial and Applied Mathematics, Series B, Numerical Analysis" }
@String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
@String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
@String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
@String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
@String{SIAMAppMath = "{SIAM} J. Appl. Math." }
@String{SIAMComp = "{SIAM} Journal on Computing" }
@String{SIAMComp = "{SIAM} J. Comput." }
@String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
@String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
@String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
@String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
@String{SIAMReview = "{SIAM} Review" }
@String{SIAMReview = "{SIAM} Rev." }
@String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical Computing" }
@String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

@String{SoftPracExp = "Software Practice and Experience" }
@String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
@String{StatScience = "Statistical Science" }
@String{StatScience = "Statist. Sci." }
@String{Techno = "Technometrics" }
@String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical Physics" }
@String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
@String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
@String{VLSICompSys = "J. {VLSI} Comput. Syst." }
@String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und Mechanik" }
@String{ZAngewMathMech = "Z. Angew. Math. Mech." }
@String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
@String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

@String{Academic = "Academic Press" }
@String{ACMPress = "{ACM} Press" }
@String{AdamHilger = "Adam Hilger" }
@String{AddisonWesley = "Addison-Wesley" }
@String{AllynBacon = "Allyn and Bacon" }
@String{AMS = "American Mathematical Society" }
@String{Birkhauser = "Birkha{\"u}ser" }
@String{CambridgePress = "Cambridge University Press" }
@String{Chelsea = "Chelsea" }
@String{ClaredonPress = "Claredon Press" }
@String{DoverPub = "Dover Publications" }
@String{Eyolles = "Eyolles" }
@String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
@String{Interscience = "Interscience" }
@String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
@String{JohnWileySons = "John Wiley and Sons" }
@String{Macmillan = "Macmillan" }
@String{MathWorks = "The Math Works Inc." }
@String{McGrawHill = "McGraw-Hill" }
@String{NatBurStd = "National Bureau of Standards" }
@String{NorthHolland = "North-Holland" }
@String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
@String{PergamonPress = "Pergamon Press" }
@String{PlenumPress = "Plenum Press" }
@String{PrenticeHall = "Prentice-Hall" }
@String{SIAMPub = "{SIAM} Publications" }
@String{Springer = "Springer-Verlag" }
@String{TexasPress = "University of Texas Press" }
@String{VanNostrand = "Van Nostrand" }
@String{WHFreeman = "W. H. Freeman and Co." }

%Entries





@article{vossel_spatial_2014,
	title = {Spatial {Attention}, {Precision}, and {Bayesian} {Inference}: {A} {Study} of {Saccadic} {Response} {Speed}},
	volume = {24},
	issn = {1460-2199, 1047-3211},
	shorttitle = {Spatial {Attention}, {Precision}, and {Bayesian} {Inference}},
	url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhs418},
	doi = {10.1093/cercor/bhs418},
	abstract = {Inferring the environment’s statistical structure and adapting behavior accordingly is a fundamental modus operandi of the brain. A simple form of this faculty based on spatial attentional orienting can be studied with Posner’s location-cueing paradigm in which a cue indicates the target location with a known probability. The present study focuses on a more complex version of this task, where probabilistic context ( percentage of cue validity) changes unpredictably over time, thereby creating a volatile environment. Saccadic response speed (RS) was recorded in 15 subjects and used to estimate subject-speciﬁc parameters of a Bayesian learning scheme modeling the subjects’ trial-by-trial updates of beliefs. Different response models—specifying how computational states translate into observable behavior—were compared using Bayesian model selection. Saccadic RS was most plausibly explained as a function of the precision of the belief about the causes of sensory input. This ﬁnding is in accordance with current Bayesian theories of brain function, and speciﬁcally with the proposal that spatial attention is mediated by a precision-dependent gain modulation of sensory input. Our results provide empirical support for precision-dependent changes in beliefs about saccade target locations and motivate future neuroimaging and neuropharmacological studies of how Bayesian inference may determine spatial attention.},
	language = {en},
	number = {6},
	urldate = {2021-11-03},
	journal = {Cerebral Cortex},
	author = {Vossel, Simone and Mathys, Christoph and Daunizeau, Jean and Bauer, Markus and Driver, Jon and Friston, Karl J. and Stephan, Klaas E.},
	month = jun,
	year = {2014},
	note = {Number: 6},
	pages = {1436--1450},
	file = {Vossel 等 - 2014 - Spatial Attention, Precision, and Bayesian Inferen.pdf:/home/zhuchangbo/Zotero/storage/39WLUFBU/Vossel 等 - 2014 - Spatial Attention, Precision, and Bayesian Inferen.pdf:application/pdf},
}

@article{newman_statistically_2023,
	title = {Statistically {Optimal} {Cue} {Integration} {During} {Human} {Spatial} {Navigation}},
	volume = {30},
	number = {5},
	journal = {Psychonomic Bulletin \& Review},
	author = {Newman, Phillip M. and Qi, Yafei and Mou, Weimin and McNamara, Timothy P.},
	year = {2023},
	pages = {1621--1642},
}


@article{Kersten2004ObjectPA,
    title={Object perception as Bayesian inference.},
    author={Daniel J. Kersten and Pascal Mamassian and Alan Loddon Yuille},
    journal={Annual review of psychology},
    year={2004},
    volume={55},
    pages={271-304}
}


@article{Zeng2020NeuroBayesSLAMNI,
	title={NeuroBayesSLAM: Neurobiologically inspired Bayesian integration of multisensory information for robot navigation},
	author={Taiping Zeng and Fengzhen Tang and Daxiong Ji and Bailu Si},
	journal={Neural networks : the official journal of the International Neural Network Society},
	year={2020},
	volume={126},
	pages={21-35}
}


@article{rumelhart1986learning,
	title={Learning representations by back-propagating errors},
	author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
	journal={Nature},
	volume={323},
	number={6088},
	pages={533--536},
	year={1986},
	doi={10.1038/323533a0},
	publisher={Nature Publishing Group UK London}
}

@article{widrow199030,
	author={Widrow, B. and Lehr, M.A.},
	journal={Proceedings of the IEEE}, 
	title={30 years of adaptive neural networks: perceptron, Madaline, and backpropagation}, 
	year={1990},
	volume={78},
	number={9},
	pages={1415-1442},
	keywords={Adaptive systems;Neural networks;Subspace constraints;Artificial neural networks;Backpropagation algorithms;History;Least squares approximation;Biological system modeling;Machine learning;Pattern recognition},
	doi={10.1109/5.58323}
}

@article{doi:10.1126/science.1127647,
	author = {G. E. Hinton  and R. R. Salakhutdinov },
	title = {Reducing the Dimensionality of Data with Neural Networks},
	journal = {Science},
	volume = {313},
	number = {5786},
	pages = {504-507},
	year = {2006},
	doi = {10.1126/science.1127647},
	URL = {https://www.science.org/doi/abs/10.1126/science.1127647},
	abstract = {High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such “autoencoder” networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.}
}
@inproceedings{NIPS2012_c399862d,
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
	pages = {},
	publisher = {Curran Associates, Inc.},
	title = {ImageNet Classification with Deep Convolutional Neural Networks},
	url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
	volume = {25},
	year = {2012},
	address={New York}
}

@INPROCEEDINGS{10.1109/IJCNN.2019.8852466,
	author={Zhao, Dongye and Si, Bailu and Tang, Fengzhen},
	booktitle={2019 International Joint Conference on Neural Networks (IJCNN)}, 
	title={Unsupervised Feature Learning for Visual Place Recognition in Changing Environments}, 
	year={2019},
	volume={},
	number={},
	pages={1-8},
	keywords={Visualization;Feature extraction;Neural networks;Task analysis;Image recognition;Unsupervised learning;Robots;visual place recognition;changing environments;unsupervised learning;siamese VisNet},
	doi={10.1109/IJCNN.2019.8852466}
}

@article{DBLP:journals/corr/Ruder16,
	author       = {Sebastian Ruder},
	title        = {An overview of gradient descent optimization algorithms},
	journal      = {CoRR},
	volume       = {abs/1609.04747},
	year         = {2016},
	url          = {http://arxiv.org/abs/1609.04747},
	eprinttype    = {arXiv},
	eprint       = {1609.04747},
	timestamp    = {Mon, 13 Aug 2018 16:48:10 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/Ruder16.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{wang2018particle,
	title={Particle swarm optimization algorithm: an overview},
	author={Wang, Dongshu and Tan, Dapei and Liu, Lei},
	journal={Soft Computing},
	volume={22},
	pages={387--408},
	year={2018},
	publisher={Springer},
	abstract = {Particle swarm optimization (PSO) is a population-based stochastic optimization algorithm motivated by intelligent collective behavior of some animals such as flocks of birds or schools of fish. Since presented in 1995, it has experienced a multitude of enhancements. As researchers have learned about the technique, they derived new versions aiming to different demands, developed new applications in a host of areas, published theoretical studies of the effects of the various parameters and proposed many variants of the algorithm. This paper introduces its origin and background and carries out the theory analysis of the PSO. Then, we analyze its present situation of research and application in algorithm structure, parameter selection, topology structure, discrete PSO algorithm and parallel PSO algorithm, multi-objective optimization PSO and its engineering applications. Finally, the existing problems are analyzed and future research directions are presented.},
	issn = {1433-7479},
	url = {https://doi.org/10.1007/s00500-016-2474-6},
	doi = {10.1007/s00500-016-2474-6},
}
@article{xu_survey_2001,
	title = {A {Survey} of {Quasi}-{Newton} {Equations} and {Quasi}-{Newton} {Methods} for {Optimization}},
	volume = {103},
	issn = {1572-9338},
	url = {https://doi.org/10.1023/A:1012959223138},
	doi = {10.1023/A:1012959223138},
	abstract = {Quasi-Newton equations play a central role in quasi-Newton methods for optimization and various quasi-Newton equations are available. This paper gives a survey on these quasi-Newton equations and studies properties of quasi-Newton methods with updates satisfying different quasi-Newton equations. These include single-step quasi-Newton equations that use only gradient information and that use both gradient and function value information in one step, and multi-step quasi-Newton equations that use the gradient information in last m steps. Main properties of quasi-Newton methods with updates satisfying different quasi-Newton equations are studied. These properties include the finite termination property, invariance, heredity of positive definite updates, consistency of search directions, global convergence and local superlinear convergence properties.},
	number = {1},
	journal = {Annals of Operations Research},
	author = {Xu, Chengxian and Zhang, Jianzhong},
	month = mar,
	year = {2001},
	pages = {213--234},
}
@INPROCEEDINGS{Kingma2014AdamAM,
author       = {Diederik P. Kingma and Jimmy Ba},
editor       = {Yoshua Bengio and Yann LeCun},
title        = {Adam: {A} Method for Stochastic Optimization},
booktitle    = {3rd International Conference on Learning Representations, {ICLR} 2015,
San Diego},
year         = {2015},
url          = {http://arxiv.org/abs/1412.6980},
timestamp    = {Thu, 25 Jul 2019 14:25:37 +0200},
biburl       = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@phdthesis{beal2003VB,
	title={Variational algorithms for approximate Bayesian inference},
	author={Beal, Matthew J},
	year={2003},
	url={https://discovery.ucl.ac.uk/id/eprint/10101435},
	school={University College London (UCL) }
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{Friston_freeEnergy_2010,
	title = {The free-energy principle: a unified brain theory?},
	volume = {11},
	issn = {1471-003X, 1471-0048},
	shorttitle = {The free-energy principle},
	doi = {10.1038/nrn2787},
	abstract = {A free-energy principle has been proposed recently that accounts for action, perception and learning. This Review looks at some key brain theories in the biological (for example, neural Darwinism) and physical (for example, information theory and optimal control theory) sciences from the free-energy perspective. Crucially, one key theme runs through each of these theories — optimization. Furthermore, if we look closely at what is optimized, the same quantity keeps emerging, namely value (expected reward, expected utility) or its complement, surprise (prediction error, expected cost). This is the quantity that is optimized under the free-energy principle, which suggests that several global brain theories might be unified within a free-energy framework.},
	language = {en},
	number = {2},
	urldate = {2020-11-27},
	journal = {Nature Reviews Neuroscience},
	author = {Friston, Karl},
	month = feb,
	year = {2010},
	pages = {127--138},
	file = {Friston - 2010 - The free-energy principle a unified brain theory.pdf:C\:\\Users\\changbo\\Zotero\\storage\\DUBLQMCH\\Friston - 2010 - The free-energy principle a unified brain theory.pdf:application/pdf},
}
@ARTICLE{Mathys2011HGF,  
	AUTHOR={Mathys, Christoph D. and Daunizeau, Jean and Friston, Karl J. and Stephan, Klaas E.},
	TITLE={A Bayesian Foundation for Individual Learning Under Uncertainty},
	JOURNAL={Frontiers in Human Neuroscience},
	VOLUME={5},
	PAGES={39},
	YEAR={2011},
	URL={https://www.frontiersin.org/article/10.3389/fnhum.2011.00039},
	DOI={10.3389/fnhum.2011.00039},
	ISSN={1662-5161},
	ABSTRACT={Computational learning models are critical for understanding mechanisms of adaptive behavior. However, the two major current frameworks, reinforcement learning (RL) and Bayesian learning, both have certain limitations. For example, many Bayesian models are agnostic of inter-individual variability and involve complicated integrals, making online learning difficult. Here, we introduce a generic hierarchical Bayesian framework for individual learning under multiple forms of uncertainty (e.g., environmental volatility and perceptual uncertainty). The model assumes Gaussian random walks of states at all but the first level, with the step size determined by the next highest level. The coupling between levels is controlled by parameters that shape the influence of uncertainty on learning in a subject-specific fashion. Using variational Bayes under a mean-field approximation and a novel approximation to the posterior energy function, we derive trial-by-trial update equations which (i) are analytical and extremely efficient, enabling real-time learning, (ii) have a natural interpretation in terms of RL, and (iii) contain parameters representing processes which play a key role in current theories of learning, e.g., precision-weighting of prediction error. These parameters allow for the expression of individual differences in learning and may relate to specific neuromodulatory mechanisms in the brain. Our model is very general: it can deal with both discrete and continuous states and equally accounts for deterministic and probabilistic relations between environmental events and perceptual states (i.e., situations with and without perceptual uncertainty). These properties are illustrated by simulations and analyses of empirical time series. Overall, our framework provides a novel foundation for understanding normal and pathological learning that contextualizes RL within a generic Bayesian scheme and thus connects it to principles of optimality from probability theory.}
}
@article{daunizeau2010observingA,
	title = {Observing the {Observer} ({I}): {Meta}-{Bayesian} {Models} of {Learning} and {Decision}-{Making}},
	volume = {5},
	issn = {1932-6203},
	shorttitle = {Observing the {Observer} ({I})},
	url = {https://dx.plos.org/10.1371/journal.pone.0015554},
	doi = {10.1371/journal.pone.0015554},
	abstract = {In this paper, we present a generic approach that can be used to infer how subjects make optimal decisions under uncertainty. This approach induces a distinction between a subject’s perceptual model, which underlies the representation of a hidden ‘‘state of affairs’’ and a response model, which predicts the ensuing behavioural (or neurophysiological) responses to those inputs. We start with the premise that subjects continuously update a probabilistic representation of the causes of their sensory inputs to optimise their behaviour. In addition, subjects have preferences or goals that guide decisions about actions given the above uncertain representation of these hidden causes or state of affairs. From a Bayesian decision theoretic perspective, uncertain representations are so-called ‘‘posterior’’ beliefs, which are influenced by subjective ‘‘prior’’ beliefs. Preferences and goals are encoded through a ‘‘loss’’ (or ‘‘utility’’) function, which measures the cost incurred by making any admissible decision for any given (hidden) state of affair. By assuming that subjects make optimal decisions on the basis of updated (posterior) beliefs and utility (loss) functions, one can evaluate the likelihood of observed behaviour. Critically, this enables one to ‘‘observe the observer’’, i.e. identify (context- or subject-dependent) prior beliefs and utility-functions using psychophysical or neurophysiological measures. In this paper, we describe the main theoretical components of this meta-Bayesian approach (i.e. a Bayesian treatment of Bayesian decision theoretic predictions). In a companion paper (‘Observing the observer (II): deciding when to decide’), we describe a concrete implementation of it and demonstrate its utility by applying it to simulated and real reaction time data from an associative learning task.},
	language = {en},
	number = {12},
	urldate = {2020-11-27},
	journal = {PLOS ONE},
	author = {Daunizeau, Jean and den Ouden, Hanneke E. M. and Pessiglione, Matthias and Kiebel, Stefan J. and Stephan, Klaas E. and Friston, Karl J.},
	editor = {Sporns, Olaf},
	month = dec,
	year = {2010},
	pages = {e15554}
}
@article{daunizeau2010observingB,
abstract = {In a companion paper [1], we have presented a generic approach for inferring how subjects make optimal decisions under uncertainty. From a Bayesian decision theoretic perspective, uncertain representations correspond to "posterior" beliefs, which result from integrating (sensory) information with subjective "prior" beliefs. Preferences and goals are encoded through a "loss" (or "utility") function, which measures the cost incurred by making any admissible decision for any given (hidden or unknown) state of the world. By assuming that subjects make optimal decisions on the basis of updated (posterior) beliefs and utility (loss) functions, one can evaluate the likelihood of observed behaviour. In this paper, we describe a concrete implementation of this meta-Bayesian approach (i.e. a Bayesian treatment of Bayesian decision theoretic predictions) and demonstrate its utility by applying it to both simulated and empirical reaction time data from an associative learning task. Here, inter-trial variability in reaction times is modelled as reflecting the dynamics of the subjects' internal recognition process, i.e. the updating of representations (posterior densities) of hidden states over trials while subjects learn probabilistic audio-visual associations. We use this paradigm to demonstrate that our meta-Bayesian framework allows for (i) probabilistic inference on the dynamics of the subject's representation of environmental states, and for (ii) model selection to disambiguate between alternative preferences (loss functions) human subjects could employ when dealing with trade-offs, such as between speed and accuracy. Finally, we illustrate how our approach can be used to quantify subjective beliefs and preferences that underlie inter-individual differences in behaviour.},
author = {Daunizeau, Jean and Ouden, Hanneke E. M. den and Pessiglione, Matthias and Kiebel, Stefan J. and Friston, Karl J. and Stephan, Klaas E.},
doi = {10.1371/journal.pone.0015555},
journal = {PLOS ONE},
keywords = {},
number = {12},
pages = {e15555},
title = {Observing the Observer (II): Deciding When to Decide},
volume = {5},
year = {2010}
}
  
@article{zhang2020brain,
	author = {Lei Zhang  and Jan Gläscher },
	title = {A brain network supporting social influences in human decision-making},
	journal = {Science Advances},
	volume = {6},
	number = {34},
	pages = {eabb4159},
	year = {2020},
	doi = {10.1126/sciadv.abb4159},
	URL = {https://www.science.org/doi/abs/10.1126/sciadv.abb4159},
	abstract = {Social influence modulates choice and confidence in learning and the interaction between the brain’s reward hub and social hub. Humans learn from their own trial-and-error experience and observing others. However, it remains unknown how brain circuits compute expected values when direct learning and social learning coexist in uncertain environments. Using a multiplayer reward learning paradigm with 185 participants (39 being scanned) in real time, we observed that individuals succumbed to the group when confronted with dissenting information but observing confirming information increased their confidence. Leveraging computational modeling and functional magnetic resonance imaging, we tracked direct valuation through experience and vicarious valuation through observation and their dissociable, but interacting neural representations in the ventromedial prefrontal cortex and the anterior cingulate cortex, respectively. Their functional coupling with the right temporoparietal junction representing instantaneous social information instantiated a hitherto uncharacterized social prediction error, rather than a reward prediction error, in the putamen. These findings suggest that an integrated network involving the brain’s reward hub and social hub supports social influence in human decision-making.}
}

@article{zhang_using_2020,
	author = {Zhang, Lei and Lengersdorff, Lukas and Mikus, Nace and Gläscher, Jan and Lamm, Claus},
	title = "{Using reinforcement learning models in social neuroscience: frameworks, pitfalls and suggestions of best practices}",
	journal = {Social Cognitive and Affective Neuroscience},
	volume = {15},
	number = {6},
	pages = {695-707},
	year = {2020},
	month = {06},
	abstract = "{The recent years have witnessed a dramatic increase in the use of reinforcement learning (RL) models in social, cognitive and affective neuroscience. This approach, in combination with neuroimaging techniques such as functional magnetic resonance imaging, enables quantitative investigations into latent mechanistic processes. However, increased use of relatively complex computational approaches has led to potential misconceptions and imprecise interpretations. Here, we present a comprehensive framework for the examination of (social) decision-making with the simple Rescorla–Wagner RL model. We discuss common pitfalls in its application and provide practical suggestions. First, with simulation, we unpack the functional role of the learning rate and pinpoint what could easily go wrong when interpreting differences in the learning rate. Then, we discuss the inevitable collinearity between outcome and prediction error in RL models and provide suggestions of how to justify whether the observed neural activation is related to the prediction error rather than outcome valence. Finally, we suggest posterior predictive check is a crucial step after model comparison, and we articulate employing hierarchical modeling for parameter estimation. We aim to provide simple and scalable explanations and practical guidelines for employing RL models to assist both beginners and advanced users in better implementing and interpreting their model-based analyses.}",
	issn = {1749-5016},
	doi = {10.1093/scan/nsaa089},
	url = {https://doi.org/10.1093/scan/nsaa089},
}
@ARTICLE{10.1109/MASSP.1986.1165342,
	author={Rabiner, L. and Juang, B.},
	journal={IEEE ASSP Magazine}, 
	title={An introduction to hidden Markov models}, 
	year={1986},
	volume={3},
	number={1},
	pages={4-16},
	abstract={The basic theory of Markov chains has been known to mathematicians and engineers for close to 80 years, but it is only in the past decade that it has been applied explicitly to problems in speech processing. One of the major reasons why speech models, based on Markov chains, have not been developed until recently was the lack of a method for optimizing the parameters of the Markov model to match observed signal patterns. Such a method was proposed in the late 1960's and was immediately applied to speech processing in several research institutions. Continued refinements in the theory and implementation of Markov modelling techniques have greatly enhanced the method, leading to a wide range of applications of these models. It is the purpose of this tutorial paper to give an introduction to the theory of Markov models, and to illustrate how they have been applied to problems in speech recognition.},
	keywords={Hidden Markov models;Linear systems;Speech processing;Speech recognition;Mathematical model;Optimization methods;Pattern matching;Time varying systems;Fluctuations},
	doi={10.1109/MASSP.1986.1165342},
	ISSN={1558-1284},
	month={Jan},
}

@article{markov1913example,
	title={An example of statistical investigation in the text of ‘Eugene Onyegin’ illustrating coupling of ‘tests’ in chains},
	author={Markov, Andrey Andreyevich},
	journal={Proceedings of the Academy of Sciences of St. Petersburg},
	volume={7},
	pages={153--162},
	year={1913}
}

@article{rawlings_modes_2003,
	title = {Modes of a {Gaussian} {Random} {Walk}},
	volume = {111},
	issn = {1572-9613},
	url = {https://doi.org/10.1023/A:1022846114843},
	doi = {10.1023/A:1022846114843},
	abstract = {It is demonstrated that a one-dimensional gaussian random walk (GRW) possesses an underlying structure in the form of random oscillatory modes. These modes are not sinusoids, but can be isolated by a well-defined procedure. They have average wavelengths and amplitudes, both of which can be determined by experiments or by theoretical calculations. This paper reports such determinations by both methods and also develops a theory that is ultimately shown to agree with experiments. Both theory and simulations show that the average wavelength and the average amplitude scale with the order of the mode in exactly the same way that the modes of the well-known Weierstrass fractal scale with mode order. This is remarkable since the wave generated by the Weierstrass function, \$\$W(x) = {\textbackslash}sum{\textbackslash}nolimits\_\{m = 1\}{\textasciicircum}{\textbackslash}infty \{({\textbackslash}tfrac\{1\}\{a\}\} ){\textasciicircum}m {\textbackslash}cos (g{\textasciicircum}m x)\$\$, is fully determined for the variable x whereas the GRW is stochastic. By increasing the size of the steps in the GRW, it is possible to selectively remove the fastest modes, while leaving the remaining modes almost unchanged. For a GRW, the parameters corresponding to a and g in the Weierstrass function are found to be 2.0 and 4.0, respectively. These values are independent of the variance associated with the GRW. Application of the random modes is reserved for a later paper.},
	number = {3},
	journal = {Journal of Statistical Physics},
	author = {Rawlings, Philip K.},
	month = may,
	year = {2003},
	pages = {769--788},
}

@article{10.1002/cplx.1041,
	author = {Najarian, Kayvan},
	title = {On learning of Sigmoid Neural Networks},
	journal = {Complexity},
	volume = {6},
	number = {4},
	pages = {39-45},
	doi = {10.1002/cplx.1041},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cplx.1041},
	abstract = {Abstract The Probably Approximately Correct (PAC) learning theory creates a framework to assess the learning properties of static models for which the data are assumed to be independently and identically distributed (i.i.d.). One important family of dynamic models to which the conventional PAC learning can not be applied is nonlinear Finite Impulse Response (FIR) models. The present article, using an extension of PAC learning that covers learning with m-dependent data, the learning properties of FIR modeling with sigmoid neural networks are evaluated. These results include upper bounds on the size of the data set required to train FIR sigmoid neural networks, provided that the input data are uniformly distributed. © 2001 John Wiley \& Sons, Inc.},
	year = {2001}
}
@INPROCEEDINGS{SAMI48414.2020.9108717,
	author={Rasamoelina, Andrinandrasana David and Adjailia, Fouzia and Sinčák, Peter},
	booktitle={2020 IEEE 18th World Symposium on Applied Machine Intelligence and Informatics (SAMI)}, 
	title={A Review of Activation Function for Artificial Neural Network}, 
	year={2020},
	volume={},
	number={},
	pages={281-286},
	keywords={Training;Artificial neural networks;Computational efficiency;Task analysis;Informatics;Machine intelligence;Activation Function;Hidden Unit;Neural Network},
	doi={10.1109/SAMI48414.2020.9108717}
}
@article{mirza2018human,
   doi = {10.1371/journal.pone.0190429},
   author = {Mirza, M. Berk AND Adams, Rick A. AND Mathys, Christoph AND Friston, Karl J.},
   journal = {PLOS ONE},
   publisher = {Public Library of Science},
   title = {Human visual exploration reduces uncertainty about the sensed world},
   year = {2018},
   month = {01},
   volume = {13},
   url = {https://doi.org/10.1371/journal.pone.0190429},
   pages = {1-20},
   abstract = {In previous papers, we introduced a normative scheme for scene construction and epistemic (visual) searches based upon active inference. This scheme provides a principled account of how people decide where to look, when categorising a visual scene based on its contents. In this paper, we use active inference to explain the visual searches of normal human subjects; enabling us to answer some key questions about visual foraging and salience attribution. First, we asked whether there is any evidence for ‘epistemic foraging’; i.e. exploration that resolves uncertainty about a scene. In brief, we used Bayesian model comparison to compare Markov decision process (MDP) models of scan-paths that did–and did not–contain the epistemic, uncertainty-resolving imperatives for action selection. In the course of this model comparison, we discovered that it was necessary to include non-epistemic (heuristic) policies to explain observed behaviour (e.g., a reading-like strategy that involved scanning from left to right). Despite this use of heuristic policies, model comparison showed that there is substantial evidence for epistemic foraging in the visual exploration of even simple scenes. Second, we compared MDP models that did–and did not–allow for changes in prior expectations over successive blocks of the visual search paradigm. We found that implicit prior beliefs about the speed and accuracy of visual searches changed systematically with experience. Finally, we characterised intersubject variability in terms of subject-specific prior beliefs. Specifically, we used canonical correlation analysis to see if there were any mixtures of prior expectations that could predict between-subject differences in performance; thereby establishing a quantitative link between different behavioural phenotypes and Bayesian belief updating. We demonstrated that better scene categorisation performance is consistently associated with lower reliance on heuristics; i.e., a greater use of a generative model of the scene to direct its exploration.},
   number = {1},
}

@article{adolphs2003cognitive,
	title = {Cognitive neuroscience of human social behaviour},
	volume = {4},
	issn = {1471-0048},
	url = {https://doi.org/10.1038/nrn1056},
	doi = {10.1038/nrn1056},
	abstract = {Regions of extrastriate cortex, including the fusiform and superior temporal gyri, are activated by biologically salient stimuli, such as faces and biological motion stimuli. A set of structures serves to modulate cognition and behaviour on the basis of the motivational properties of stimuli. This set includes the amygdala, the ventral striatum and the orbitofrontal cortex. Reasoning about, volitional guidance of, and self-regulation of social behaviour draws on regions of the brain that represent emotional response and actions, and that integrate goals with behaviour. These include right somatosensory cortices, the left frontal operculum and anterior cingulate cortices. Pathological social behaviour is seen in diseases ranging from autism to psychopathy. Although most such disorders are heterogeneous in etiology, the amygdala and prefrontal cortex have been implicated in their development.},
	number = {3},
	journal = {Nature Reviews Neuroscience},
	author = {Adolphs, Ralph},
	month = mar,
	year = {2003},
	pages = {165--178},
}

@article{YAU2023107799,
	title = {The Rescorla-Wagner model, prediction error, and fear learning},
	journal = {Neurobiology of Learning and Memory},
	volume = {203},
	pages = {107799},
	year = {2023},
	issn = {1074-7427},
	doi = {10.1016/j.nlm.2023.107799},
	url = {https://www.sciencedirect.com/science/article/pii/S1074742723000801},
	author = {Joanna Oi-Yue Yau and Gavan P. McNally},
	abstract = {The Rescorla-Wagner model remains one of the most important and influential theoretical accounts of the conditions under which Pavlovian learning occurs. Moreover, the experimental approaches that inspired the model continue to provide powerful behavioral tools to advance mechanistic understanding of how we and other animals learn to fear and learn to reduce fear. Here we consider key features of the Rescorla-Wagner model as applied to study of fear learning. We review evidence for key insights of the model. First, learning to fear and learning to reduce fear are governed by a common, signed prediction error. Second, this error drives variations in effectiveness of the shock US that are causal to whether and how much fear is learned or lost during a conditioning trial. We also consider behavioral and neural findings inconsistent with the model and which will be essential to understand and advance understanding of fear learning.}
}
@article{walkenbach1980rescorla,
	title={The Rescorla-Wagner theory of conditioning: A review of the literature},
	author={Walkenbach, John and Haddad, Nabil F},
	journal={The Psychological Record},
	volume={30},
	number={4},
	pages={497--509},
	year={1980},
}
@article{hill2017causal,
	title={A causal account of the brain network computations underlying strategic social behavior},
	author={Hill, Christopher A and Suzuki, Shinsuke and Polania, Rafael and Moisa, Marius and O'doherty, John P and Ruff, Christian C},
	journal={Nature Neuroscience},
	volume={20},
	number={8},
	pages={1142--1149},
	year={2017},
	doi={10.1038/nn.4602},
	url = {https://doi.org/10.1038/nn.4602},
	issn = {1546-1726},
	abstract={The authors show that transcranial magnetic disruption of the right temporoparietal junction decreases strategic behavior during competitive interactions. The altered behavior relates to neural activity changes both locally and in interconnected prefrontal areas. These brain networks may causally underlie the ability to predict the behavior of other agents.}
}


@article{de2005tutorial,
	title={A tutorial on the cross-entropy method},
	author={De Boer, Pieter-Tjerk and Kroese, Dirk P and Mannor, Shie and Rubinstein, Reuven Y},
	journal={Annals of Operations Research},
	volume={134},
	pages={19--67},
	year={2005},
	publisher={Springer},
	isbn = {1572-9338},
	url = {https://doi.org/10.1007/s10479-005-5724-z},
	doi = {10.1007/s10479-005-5724-z},
	abstract = {The cross-entropy (CE) method is a new generic approach to combinatorial and multi-extremal optimization and rare event simulation. The purpose of this tutorial is to give a gentle introduction to the CE method. We present the CE methodology, the basic algorithm and its modifications, and discuss applications in combinatorial optimization and machine learning.},
}
@inproceedings{10.1145/1102351.1102422,
	author = {Mannor, Shie and Peleg, Dori and Rubinstein, Reuven},
	title = {The cross entropy method for classification},
	year = {2005},
	isbn = {1595931805},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1102351.1102422},
	doi = {10.1145/1102351.1102422},
	abstract = {We consider support vector machines for binary classification. As opposed to most approaches we use the number of support vectors (the "L0 norm") as a regularizing term instead of the L1 or L2 norms. In order to solve the optimization problem we use the cross entropy method to search over the possible sets of support vectors. The algorithm consists of solving a sequence of efficient linear programs. We report experiments where our method produces generalization errors that are similar to support vector machines, while using a considerably smaller number of support vectors.},
	booktitle = {Proceedings of the 22nd International Conference on Machine Learning},
	pages = {561–568},
	numpages = {8},
	location = {Bonn, Germany},
	series = {ICML '05}
}

@article{AMARI1993185,
	title = {Backpropagation and stochastic gradient descent method},
	journal = {Neurocomputing},
	volume = {5},
	number = {4},
	pages = {185-196},
	year = {1993},
	issn = {0925-2312},
	doi = {https://doi.org/10.1016/0925-2312(93)90006-O},
	url = {https://www.sciencedirect.com/science/article/pii/092523129390006O},
	author = {Shun-ichi Amari},
	keywords = {Stochastic descent, generalized delta rule, dynamics of learning, pattern classification, multilayer perceptron},
	abstract = {The backpropagation learning method has opened a way to wide applications of neural network research. It is a type of the stochastic descent method known in the sixties. The present paper reviews the wide applicability of the stochastic gradient descent method to various types of models and loss functions. In particular, we apply it to the pattern recognition problem, obtaining a new learning algorithm based on the information criterion. Dynamical properties of learning curves are then studied based on an old paper by the author where the stochastic descent method was proposed for general multilayer networks. The paper is concluded with a short section offering some historical remarks.}
}


@article{10.1145/192115.192132,
	author = {Mor\'{e}, Jorge J. and Thuente, David J.},
	title = {Line search algorithms with guaranteed sufficient decrease},
	year = {1994},
	issue_date = {Sept. 1994},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {20},
	number = {3},
	issn = {0098-3500},
	url = {https://doi.org/10.1145/192115.192132},
	doi = {10.1145/192115.192132},
	abstract = {The development of software for minimization problems is often based on a line search method. We consider line search methods that satisfy sufficient decrease and curvature conditions, and formulate the problem of determining a point that satisfies these two conditions in terms of finding a point in a set T(μ).  We describe a search algorithm for this problem that produces a sequence of iterates that converge to a point in T(μ) and that, except for pathological cases, terminates in a finite number of steps. Numerical results for an implementation of the search algorithm on a set of test functions show that the algorithm terminates within a small number of iterations.},
	journal = {ACM Trans. Math. Softw.},
	month = {sep},
	pages = {286–307},
	numpages = {22},
	keywords = {conjugate gradient algorithms, line search algorithms, nonlinear optimization, truncated Newton algorithms, variable metric algorithms}
}

@article{baum_statistical_1966,
	title = {Statistical {Inference} for {Probabilistic} {Functions} of {Finite} {State} {Markov} {Chains}},
	volume = {37},
	issn = {00034851},
	url = {http://www.jstor.org/stable/2238772},
	number = {6},
	urldate = {2024-03-03},
	journal = {The Annals of Mathematical Statistics},
	author = {Baum, Leonard E. and Petrie, Ted},
	year = {1966},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {1554--1563},
}


@article{schwarz1978estimating,
	author = {Gideon Schwarz},
	title = {{Estimating the Dimension of a Model}},
	volume = {6},
	journal = {The Annals of Statistics},
	number = {2},
	publisher = {Institute of Mathematical Statistics},
	pages = {461 -- 464},
	keywords = {Akaike information criterion, asymptotics, dimension},
	year = {1978},
	doi = {10.1214/aos/1176344136},
	URL = {https://doi.org/10.1214/aos/1176344136}
}
@article{Dubrovin1906,
    author = { Дубровин, А. И },
    title = { Открытое письмо Председателя Главного Совета Союза Русского Народа Санкт-Петербургскому Антонию, Первенствующему члену Священного Синода },
    journal = { Вече },
    year = { 1906 },
    volume = {  },
    edition = { 97 },
    month = { 7 дек. 1906 },
    pages = { 1-3 },
    hyphenation = { russian },
    language = { russian }
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@Book{nocewrig2006Numerical,
	series={Springer Series in Operations Research and Financial Engineering},
	title={Numerical {O}ptimization},
	year={2006},
	papes={636},
	publisher={Spinger},
	author= {Jorge Nocedal and Stephen J. Wright},
	address= {New York},
	edition= {second},
	doi={10.1007/b98874},
}
% probability theory and Stochastic processes
@book{kingman1992poisson,
series={Oxford Studies in Probability},
title={Poisson {P}rocesses},
year={1993},
papes={104},
publisher={Oxford University Press},
author= {Kingman, John Frank Charles},
address= {New York},
edition= {first},
ISBN={0-19-853693-3},
}

@book{ibe2014fundamentals,
title={Fundamentals of {A}pplied {P}robability and {R}andom {P}rocesses},
author={Ibe Oliver C.},
edition={second},
year={2014},
publisher={Academic Press},
address= {Boston},
isbn={9780128010358},
}
@book{tuckwell1989stochastic,
author = {Tuckwell, Henry C.},
title = {Stochastic {P}rocesses in the {N}eurosciences},
publisher = {Society for Industrial and Applied Mathematics},
year = {1989},
doi = {10.1137/1.9781611970159},
address = {Philadelphia},
edition   = {},
pages={140},
}

@book{kao1997introduction,
title={An {I}ntroduction to {S}tochastic {P}rocesses},
author={Kao, Edward PC},
isbn={9780534255183},
lccn={96018157},
series={Business Statistics Series},
year={1997},
pages={438},
publisher={Duxbury Press},
address={Belmont,Calif.},
}
@book{evans2012introduction,
title={An {I}ntroduction to {S}tochastic {D}ifferential {E}quations},
author={Evans, Lawrence C},
isbn={9781470410544},
lccn={2013024818},
year={2012},
pages={133},
publisher={American Mathematical Society},
address={Providence, Rhode Island},
}

@book{feynman1972statistical,
series={Frontiers in Physics},
edition = {first},
author={Feynman, Richard Phillips},
title={Statistical {M}echanics {A} {S}et {O}f {L}ectures},
isbn={ 9780805325096},
pages={354},
year={1972},
publisher={W. A. Benjamin},
address={Reading, Massachusetts},
}

@book{ando2010bayesian,
title={{Bayesian {M}odel {S}election and {S}tatistical {M}odeling}},
author={Ando, Tomohiro},
year={2010},
publisher={CRC Press},
address={New York},
doi={10.1201/EBK1439836149},
isbn={9780429106286},
pages={300},
}
@book{johnson2002applied,
title={Applied multivariate statistical analysis},
author={Johnson, Richard Arnold and Wichern, Dean W},
edition={sixth},
pages={808},
year={2008},
ISBN-13={9780131877153},
publisher={Pearson},
Address= {Upper Saddle River, New Jersey},
}
@book{sutton2018reinforcement,
title={Reinforcement {L}earning: {A}n I{}ntroduction},
edition={second},
url={http://incompleteideas.net/book/RLbook2020trimmed.pdf},
papges={526},
author={Sutton, Richard S and Barto, Andrew G},
year={2018},
publisher={MIT Press},
address={Cambridge, MA},
ISBN={9780262039246}	
}
@book{goodfellow2016book,
title={{Deep Learning}},
author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
publisher={MIT Press},
note={\url{http://www.deeplearningbook.org}},
year={2016},
address={Cambridge, MA},
isbn={9780262035613},
pages={800},
}
@book{von1860handbuch,
title={{Handbuch der physiologischen Optik}},
author={Helmholtz, Hermann von and Wilibald a Nagel},
pages={874},
address={Leipzig},
publisher={Leopold Voss},
year={1867},
Language={German}
}
@book{fechner1860elemente,
title={Elemente der psychophysik},
author={Fechner, Gustav Theodor},
volume={2},
year={1860},	
address={Leipzig},
publisher={Breitkopf und H{\"a}rtel}
}
@book{golub2013Compmatrix,
title={Matrix computations Fourth edition. Johns Hopkins studies in the mathematical sciences},
author={Golub, Gene H and Van Loan, Charles F},
year={2013},
publisher={Johns Hopkins University Press},
address={Baltimore, MD},
}

@book{matThm_zhang2013,
title={矩阵分析与应用},
author={张贤达},
key={Xianda Zhang},
year={2013},
address={北京},
edition = { 2 },
publisher={清华大学出版社}
}

@book{wei2021_bayesian,
series={中国科学技术大学精品教材},
title={贝叶斯分析},
author={韦来生 and 张伟平},
key={Laisheng Wei},
year={2021},
address={合肥},
edition = { 2 },
publisher={中国科学技术大学出版社}
}
@book{harold1961theory,
author={Jeffreys, Harold},
title={Theory of {P}robability},
publisher={Oxford University Press},
year={1998},
month={08},
edition={second},
abstract ={Jeffreys' Theory of Probability, first published in 1939, was the first attempt to develop a fundamental theory of scientific inference based on Bayesian statistics. His ideas were well ahead of their time and it is only in the past ten years that the subject of Bayes' factors has been significantly developed and extended. Recent work has made Bayesian statistics an essential subject for graduate students and researchers. This seminal book is their starting point.},
isbn = {9780198503682},
doi = {10.1093/oso/9780198503682.001.0001},
address={London},
}
}
@book{carpenter2022_game,
title={{Game Theory and Behavior}},
author={Jeffrey Carpenter and Andrea Robbett },
year={2022},
pages={768},
isbn={9780262047296},
publisher={MIT Press},
address = {Cambridge, MA},
}
@book{knill1996perception,
title={Perception as {B}ayesian inference},
author={Knill, David C and Richards, Whitman},
year={1996},
isbn={9780521461092},
lccn={lc96018905},
publisher={Cambridge University Press},
address = {New York, NY},
}
@book{berger2013statistical,
series={Springer Series in Statistics},
edition = {second},
title={{Statistical decision theory and Bayesian analysis}},
author={Berger, James O},
year={2010},
publisher={Springer},
address = {New York, NY},
doi={10.1007/978-1-4757-4286-2},
ISBN={9781441930743},
pages={618},
}
